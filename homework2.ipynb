{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810a8cd67f51115",
   "metadata": {},
   "source": [
    "# **요구사항 1: titanic dataset.py 분석하기**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c36e0e1995ae1d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566209e3f07acfec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:22.340734Z",
     "start_time": "2024-10-18T07:42:22.319790Z"
    }
   },
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset): ## 훈련 및 검증 데이터셋용\n",
    "  def __init__(self, X, y): \n",
    "    self.X = torch.FloatTensor(X) ## 입력 데이터를 FloatTensor로 변환\n",
    "    self.y = torch.LongTensor(y) ## 타겟 데이터를 LongTensor로 변환\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X) ## 데이터셋의 크기 반환\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx] ## 해당 인덱스의 입력 데이터 가져오기\n",
    "    target = self.y[idx] ## 해당 인덱스의 타겟 데이터 가져오기\n",
    "    return {'input': feature, 'target': target} ## 'input'과 'target'으로 구성된 딕셔너리 반환\n",
    "\n",
    "  def __str__(self):\n",
    "    ## 데이터셋 정보 반환\n",
    "    str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "      len(self.X), self.X.shape, self.y.shape\n",
    "    )\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851c964816fc9b4",
   "metadata": {},
   "source": [
    "- 이 코드는 훈련 및 검증 데이터셋용 클래스이다. 데이터 초기화, 데이터셋 크기 반환, 입력받은 인덱스의 데이터 가져오기, 데이터셋의 정보 출력을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1276f8e8fe08f502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:26.810656Z",
     "start_time": "2024-10-18T07:42:26.793660Z"
    }
   },
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset): ## 테스트 데이터셋용\n",
    "  def __init__(self, X):\n",
    "    self.X = torch.FloatTensor(X)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx]\n",
    "    return {'input': feature} ## 타겟 없이 입력 데이터만 반환\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "      len(self.X), self.X.shape\n",
    "    )\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a8cb81bc08ad2",
   "metadata": {},
   "source": [
    "- 이 코드는 테스트 데이터셋용 클래스이다. 데이터 초기화, 데이터셋 크기 반환, 입력받은 인덱스의 데이터 가져오기, 데이터셋의 정보 출력을 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "572a5ccdc9485327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:29.036309Z",
     "start_time": "2024-10-18T07:42:29.022004Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset():  ## 전처리된 데이터셋 불러오기\n",
    "    CURRENT_FILE_PATH = os.getcwd() ##아래 코드는 jupyter notebook에서 오류가 발생하기 때문에 현재 작업 디렉토리를 이용하도록 바꿔주었다.\n",
    "    ##CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    train_df = pd.read_csv(train_data_path) ## 훈련 데이터 읽기\n",
    "    test_df = pd.read_csv(test_data_path) ## 테스트 데이터 읽기\n",
    "\n",
    "    all_df = pd.concat([train_df, test_df], sort=False) ## concat으로 데이터 병합\n",
    "\n",
    "    ## 데이터 전처리 과정 실행\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True) ## 훈련용 입력 데이터셋\n",
    "    ## Survived 값이 기록되어 있는 데이터만을 선택하여 훈련 데이터셋으로 사용한다. Survived 열을 제거하여 입력 데이터만 남긴다. 모델 학습에 사용될 타겟 데이터다. 기존 인덱스를 제거하고, 새로 인덱스를 0부터 다시 부여한다.\n",
    "    train_y = train_df[\"Survived\"] ## 훈련용 타겟 데이터셋\n",
    "    ## 훈련 데이터에서 타겟 값인 Survived 열을 가져온다. \n",
    "\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True) ## 테스트용 입력 데이터셋\n",
    "    ## Survived 값이 비어있는 데이터만 선택하여 테스트 데이터셋으로 사용한다. Survived 열을 제거하여 입력 데이터만 남긴다. 예측을 위해 모델에 입력될 값들이다. 기존 인덱스를 제거하고, 새로 인덱스를 0부터 다시 부여한다.\n",
    "\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values) ## 훈련 데이터셋 생성\n",
    "    #print(dataset)\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2]) ## 훈련 데이터셋과 검증 데이터셋을 랜덤으로 8:2로 분할\n",
    "    test_dataset = TitanicTestDataset(test_X.values) ## 테스트 데이터셋 생성\n",
    "    #print(test_dataset)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset ## 각 데이터셋 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e12c66cca469a3",
   "metadata": {},
   "source": [
    "- Titanic dataset을 전처리한 후, 훈련, 검증, 테스트 데이터셋을 생성하여 반환하는 작업을 수행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99aba4f3daa77408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:31.660595Z",
     "start_time": "2024-10-18T07:42:31.647015Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_1(all_df):\n",
    "    # Pclass별 Fare 평균값을 사용하여 Fare 결측치 메우기\n",
    "    ## Fare 열의 결측치를 같은 Pclass(티켓 등급) 그룹별 평균으로 채움\n",
    "    \n",
    "    ## Pclass별 평균 Fare 값을 계산하여 새로운 데이터프레임 생성\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    ## 컬럼 이름을 Pclass와 Fare_mean으로 변경\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    ## Pclass를 기준으로 원본 데이터와 평균 Fare 값을 결합\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    ## Fare 값이 비어있을 경우, 해당 Pclass의 평균 Fare 값으로 대체\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4debff2887dfc9",
   "metadata": {},
   "source": [
    "- 전처리 과정 1: 티켓 등급(Pclass)에 따른 Fare의 평균값을 계산하여 비어있는 Fare 값(결측값)을 해당 등급의 평균 운임 값으로 채운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "584352b01063de19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:33.626912Z",
     "start_time": "2024-10-18T07:42:33.606592Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_2(all_df):\n",
    "    # name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침\n",
    "    ## Name 컬럼을 family_name, honorific, name으로 분리\n",
    "    \n",
    "    ## 이름을 쉼표와 점을 기준으로 세 개의 부분으로 분리\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    ## 새로 생성된 데이터프레임에 각 부분에 대한 컬럼 이름 부여\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    ## 각 컬럼의 앞뒤 공백을 제거하여 깔끔한 데이터를 만듦\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    ## 기존 데이터프레임에 분리된 이름 데이터프레임을 추가\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19272b840c3267b5",
   "metadata": {},
   "source": [
    "- 전처리 과정 2: 승객의 이름을 세 개의 컬럼(family_name, honorific, name)으로 분리하고, 기존 데이터에 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d255c07d803ff36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:35.276257Z",
     "start_time": "2024-10-18T07:42:35.269276Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_3(all_df):\n",
    "    # honorific별 Age 평균값을 사용하여 Age 결측치 메우기\n",
    "\n",
    "    ## honorific별 중앙값을 계산하고 소수점 첫째 자리에서 반올림\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    ## 컬럼 이름을 honorific과 그에 따른 나이 평균값으로 변경\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\", ]\n",
    "    ## honorific을 기준으로 원본 데이터와 중앙 나이 값을 결합\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    ## 나이 값이 결측값인 경우, 해당 honorific의 중앙 나이 값으로 대체\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "    ## 나이 중앙값 컬럼은 더 이상 필요하지 않으므로 삭제\n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd1d5a46c59776",
   "metadata": {},
   "source": [
    "- 전처리 과정 3: 승객의 honorific(경칭)에 따른 Age(나이)의 중앙값을 사용하여 결측된 나이 값을 채운다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af830771e2d22d53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:37.931572Z",
     "start_time": "2024-10-18T07:42:37.911729Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # 가족수(family_num) 컬럼 새롭게 추가\n",
    "    ## 가족수 및 혼자 탑승 여부 컬럼 추가\n",
    "\n",
    "    ## SibSp(형제자매/배우자)와 Parch(부모/자녀)를 더해 family_num(가족 수) 컬럼 생성\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "\n",
    "    # 혼자탑승(alone) 컬럼 새롭게 추가\n",
    "    ## 가족 수가 0이면 혼자 탑승했다는 의미로 alone 컬럼에 1을 넣음\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    ## 혼자가 아닌 경우는 0으로 처리\n",
    "    all_df[\"alone\"] = all_df[\"alone\"].fillna(0) ##pandas 3.0에서는 inplace=True 방식이 더 이상 제대로 동작하지 않기 때문에 이 코드로 대체하였다.\n",
    "    ##all_df[\"alone\"].fillna(0, inplace=True)\n",
    "\n",
    "    # 학습에 불필요한 컬럼 제거\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1ac8778472a5e",
   "metadata": {},
   "source": [
    "- 전처리 과정 4: 가족 수와 혼자 탑승했는지 여부를 나타내는 컬럼을 추가하고, 학습에 불필요한 컬럼을 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63723d4e5a5ee263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:22:43.466081Z",
     "start_time": "2024-10-18T12:22:43.445097Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_5(all_df):\n",
    "    # honorific 값 개수 줄이기\n",
    "    ## honorific 값 축소 및 Embarked 결측값 처리\n",
    "    \n",
    "    ## 자주 사용되는 honorific만 남기고 나머지는 other로 대체\n",
    "    all_df.loc[\n",
    "    ~(\n",
    "            (all_df[\"honorific\"] == \"Mr\") |\n",
    "            (all_df[\"honorific\"] == \"Miss\") |\n",
    "            (all_df[\"honorific\"] == \"Mrs\") |\n",
    "            (all_df[\"honorific\"] == \"Master\")\n",
    "    ),\n",
    "    \"honorific\"\n",
    "    ] = \"other\"\n",
    "    ## Embarked 값의 결측치는 missing이라는 값으로 대체\n",
    "    all_df[\"Embarked\"] = all_df[\"Embarked\"].fillna(\"missing\") ##pandas 3.0에서는 inplace=True 방식이 더 이상 제대로 동작하지 않기 때문에 이 코드로 대체하였다.\n",
    "    ##all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e946f0e1a4215d6",
   "metadata": {},
   "source": [
    "- 전처리 과정 5: honorific의 값 개수를 줄이고, Embarked(탑승 항구) 값의 결측치는 missing으로 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2328a72980beb354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:41.513268Z",
     "start_time": "2024-10-18T07:42:41.503295Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_6(all_df):\n",
    "    # 카테고리 변수를 LabelEncoder를 사용하여 수치값으로 변경하기\n",
    "    \n",
    "    ## all_df 데이터프레임에서 데이터 타입이 object(문자열)인 컬럼만 선택\n",
    "    ## 이를 통해 카테고리형 변수를 식별한다.\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    ## LabelEncoder는 각 문자열 값을 0부터 시작하는 정수값으로 매핑하여 변환한다.\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        ## 각 카테고리형 변수에 대해 LabelEncoder 생성\n",
    "        le = LabelEncoder()\n",
    "        ## 해당 컬럼이 문자열 타입인지 확인\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "          ## LabelEncoder를 사용하여 해당 컬럼의 고유한 값들을 학습(fit)\n",
    "          ## 고유한 문자열 값을 각각 0부터 시작하는 정수값으로 매핑\n",
    "          le = le.fit(all_df[category_feature])\n",
    "          ## 학습된 LabelEncoder를 사용하여, 해당 컬럼의 문자열 값을 숫자로 변환\n",
    "          ## 변환된 값은 원래의 문자열 대신 수치로 대체\n",
    "          all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cacdcf4ea58cf1",
   "metadata": {},
   "source": [
    "- 전처리 과정 6: 카테고리 변수를 LabelEncoder를 사용하여 수치값으로 변경한다. 이 작업을 통해 모델에 입력가능한 형태로 변환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89ed6526df03eae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:42.878383Z",
     "start_time": "2024-10-18T07:42:42.860431Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__() ## 부모 클래스(nn.Module)의 생성자를 호출하여 초기화\n",
    "\n",
    "    ##neural network 정의\n",
    "    self.model = nn.Sequential( ##수정 가능\n",
    "      ## input, hidden1, hidden2, output\n",
    "      nn.Linear(n_input, 30), ## 1-2 layer\n",
    "      nn.ReLU(), ## 활성화 함수 ReLU\n",
    "      nn.Linear(30, 30), ## 2-3 layer\n",
    "      nn.ReLU(), ## 활성화 함수 ReLU\n",
    "      nn.Linear(30, n_output), ## 3-4 layer\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    ## 순전파 함수. 입력 데이터를 받아 모델의 각 층을 통과시키는 역할\n",
    "    x = self.model(x) ## 신경망을 통해 입력 x를 처리\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28737b353ac35e1d",
   "metadata": {},
   "source": [
    "- 2개의 hidden layer를 가지는 feedforward neural network를 설계한다. Linear 층과 ReLU 활성화 함수로 구성되어 있으며, 순전파 시 입력 데이터를 받아 최종 예측 값을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0d4c09dfb10838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:42:44.823931Z",
     "start_time": "2024-10-18T07:42:44.809927Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(test_data_loader):\n",
    "  ## 테스트 함수, 테스트용 데이터 로더에서 데이터를 받아 모델 예측 수행\n",
    "  print(\"[TEST]\")\n",
    "  ## 테스트 데이터 로더에서 첫 번째 배치를 가져옴\n",
    "  batch = next(iter(test_data_loader))\n",
    "  ## 배치 내 input 데이터의 크기(Shape)를 출력, 모델 입력으로 어떤 형태의 데이터가 들어오는지 확인 가능\n",
    "  print(\"{0}\".format(batch['input'].shape))\n",
    "  ## 입력 크기 11, 출력 크기 2를 가진 MyModel 생성\n",
    "  my_model = MyModel(n_input=11, n_output=2)\n",
    "  ## 모델에 입력 데이터를 넣고 예측값을 계산\n",
    "  ## output_batch에는 모델의 출력값이 저장됨\n",
    "  output_batch = my_model(batch['input'])\n",
    "  ## 예측값(output_batch)에서 가장 큰 값을 prediction_batch로 \n",
    "  prediction_batch = torch.argmax(output_batch, dim=1)\n",
    "  ## 예측된 값들을 892번부터 하나씩 출력\n",
    "  for idx, prediction in enumerate(prediction_batch, start=892):\n",
    "      print(idx, prediction.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deca4a86d439d44",
   "metadata": {},
   "source": [
    "- 테스트 데이터 로더로부터 데이터를 불러와 모델을 사용하여 예측을 수행한 후 각 데이터의 예측값을 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:53:17.456501Z",
     "start_time": "2024-10-18T07:53:17.175160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 713, validation_dataset.shape: 178, test_dataset: 418\n",
      "################################################## 1\n",
      "0 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "1 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.3625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "2 - tensor([ 3.0000,  1.0000, 38.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "3 - tensor([ 2.0000,  1.0000, 36.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "4 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "5 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "6 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 34.0208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "7 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "8 - tensor([ 2.0000,  0.0000, 19.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "9 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "10 - tensor([ 2.0000,  1.0000, 37.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "11 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "12 - tensor([ 2.0000,  0.0000,  3.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "13 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 110.8833,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "14 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "15 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "16 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "17 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "18 - tensor([ 1.0000,  1.0000, 38.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "19 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "20 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "21 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 151.5500,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "22 - tensor([ 1.0000,  1.0000, 71.0000,  0.0000,  0.0000, 34.6542,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "23 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.1417,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "24 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "25 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         0.0000,  4.0000,  0.0000]): 0\n",
      "26 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "27 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "28 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "29 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "30 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "31 - tensor([  1.0000,   0.0000,  42.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "32 - tensor([ 3.0000,  1.0000,  1.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "33 - tensor([ 3.0000,  0.0000,  6.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "34 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "35 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "36 - tensor([ 2.0000,  0.0000, 32.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "37 - tensor([  1.0000,   1.0000,  17.0000,   0.0000,   2.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 1\n",
      "38 - tensor([  1.0000,   0.0000,  31.0000,   0.0000,   2.0000, 164.8667,   2.0000,\n",
      "         87.5090,   1.0000,   2.0000,   0.0000]): 1\n",
      "39 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "40 - tensor([ 3.0000,  1.0000, 47.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "41 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8875,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "42 - tensor([ 1.0000,  0.0000, 22.0000,  0.0000,  1.0000, 55.0000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "43 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "44 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "45 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 15.0458,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "46 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "47 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "48 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "49 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "50 - tensor([ 3.0000,  1.0000, 74.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "51 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "52 - tensor([ 2.0000,  1.0000, 54.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "53 - tensor([ 1.0000,  1.0000, 42.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "54 - tensor([ 3.0000,  1.0000, 20.0000,  1.0000,  1.0000, 15.7417,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "55 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "56 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.9500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "57 - tensor([ 2.0000,  1.0000, 43.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "58 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "59 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.3875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "60 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "61 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "62 - tensor([ 1.0000,  1.0000, 26.0000,  0.0000,  0.0000, 30.0000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "63 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "64 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "65 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "66 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "67 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.8625,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "68 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 27.7208,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "69 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "70 - tensor([ 2.0000,  0.0000, 33.0000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "71 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "72 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "73 - tensor([ 3.0000,  0.0000,  4.0000,  1.0000,  1.0000, 16.7000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "74 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "75 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "76 - tensor([ 2.0000,  0.0000, 30.0000,  3.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "77 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  3.0000, 19.2583,  0.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "78 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "79 - tensor([ 1.0000,  0.0000, 22.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "80 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "81 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "82 - tensor([ 3.0000,  0.0000, 45.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "83 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "84 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "85 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "86 - tensor([ 2.0000,  1.0000, 32.5000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "87 - tensor([ 3.0000,  1.0000, 16.0000,  1.0000,  3.0000, 34.3750,  2.0000, 13.3029,\n",
      "         2.0000,  4.0000,  0.0000]): 0\n",
      "88 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "89 - tensor([  1.0000,   1.0000,  58.0000,   0.0000,   2.0000, 113.2750,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "90 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "91 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "92 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "93 - tensor([  1.0000,   1.0000,  50.0000,   2.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   4.0000,   2.0000,   0.0000]): 1\n",
      "94 - tensor([ 1.0000,  1.0000, 21.0000,  0.0000,  1.0000, 77.2875,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "95 - tensor([ 2.0000,  0.0000, 23.0000,  0.0000,  0.0000, 13.7917,  0.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "96 - tensor([ 3.0000,  1.0000, 22.0000,  1.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "97 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.1708,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "98 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "99 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "100 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "101 - tensor([ 2.0000,  0.0000, 27.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "102 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.4833,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "103 - tensor([  1.0000,   1.0000,  24.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "104 - tensor([ 3.0000,  1.0000, 59.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "105 - tensor([ 1.0000,  1.0000, 50.0000,  1.0000,  0.0000, 55.9000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "106 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "107 - tensor([ 3.0000,  0.0000,  5.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 1\n",
      "108 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "109 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 11.1333,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "110 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "111 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "112 - tensor([ 1.0000,  0.0000, 22.0000,  0.0000,  2.0000, 49.5000,  0.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "113 - tensor([ 3.0000,  1.0000, 34.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "114 - tensor([ 1.0000,  1.0000, 80.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "115 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "116 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "117 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "118 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "119 - tensor([ 3.0000,  0.0000, 14.5000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "120 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "121 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "122 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "123 - tensor([ 1.0000,  0.0000, 19.0000,  0.0000,  2.0000, 26.2833,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "124 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "125 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 221.7792,   2.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "126 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  8.3000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "127 - tensor([ 1.0000,  1.0000, 27.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "128 - tensor([ 3.0000,  0.0000, 17.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "129 - tensor([ 1.0000,  0.0000, 38.0000,  0.0000,  0.0000, 80.0000,  3.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "130 - tensor([ 3.0000,  1.0000, 14.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         2.0000,  7.0000,  0.0000]): 0\n",
      "131 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "132 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "133 - tensor([ 3.0000,  0.0000, 25.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "134 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "135 - tensor([ 3.0000,  0.0000, 26.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "136 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "137 - tensor([ 3.0000,  1.0000, 70.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "138 - tensor([  1.0000,   1.0000,  49.0000,   1.0000,   1.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "139 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "140 - tensor([ 3.0000,  1.0000, 34.5000,  0.0000,  0.0000,  6.4375,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "141 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "142 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "143 - tensor([ 2.0000,  0.0000, 54.0000,  1.0000,  3.0000, 23.0000,  2.0000, 21.1792,\n",
      "         3.0000,  4.0000,  0.0000]): 1\n",
      "144 - tensor([ 2.0000,  0.0000, 45.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "145 - tensor([ 3.0000,  0.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 0\n",
      "146 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "147 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "148 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "149 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  1.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "150 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "151 - tensor([ 3.0000,  0.0000, 47.0000,  1.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "152 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 0\n",
      "153 - tensor([ 3.0000,  0.0000, 14.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "154 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "155 - tensor([ 3.0000,  1.0000, 26.0000,  2.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "156 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "157 - tensor([  1.0000,   0.0000,  30.0000,   0.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "158 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "159 - tensor([  1.0000,   0.0000,  25.0000,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   3.0000,   3.0000,   0.0000]): 0\n",
      "160 - tensor([ 1.0000,  1.0000, 25.0000,  1.0000,  0.0000, 91.0792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "161 - tensor([ 2.0000,  1.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "162 - tensor([ 3.0000,  0.0000, 28.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "163 - tensor([  1.0000,   1.0000,  50.0000,   1.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "164 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "165 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "166 - tensor([ 2.0000,  0.0000,  6.0000,  0.0000,  1.0000, 33.0000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "167 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "168 - tensor([ 3.0000,  1.0000, 65.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "169 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 17.4000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "170 - tensor([ 1.0000,  0.0000, 54.0000,  1.0000,  0.0000, 78.2667,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "171 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "172 - tensor([ 3.0000,  0.0000,  9.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "173 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.8458,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "174 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 40.1250,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "175 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000, 20.2125,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "176 - tensor([ 3.0000,  1.0000, 30.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "177 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 15.7500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "178 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "179 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "180 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7292,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "181 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "182 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "183 - tensor([ 1.0000,  1.0000, 40.0000,  0.0000,  0.0000, 31.0000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "184 - tensor([ 2.0000,  1.0000, 32.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "185 - tensor([ 2.0000,  1.0000, 48.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "186 - tensor([  1.0000,   0.0000,  40.0000,   0.0000,   0.0000, 153.4625,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "187 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "188 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "189 - tensor([ 3.0000,  0.0000,  0.7500,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "190 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "191 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "192 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "193 - tensor([ 3.0000,  0.0000,  3.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "194 - tensor([ 3.0000,  0.0000,  1.0000,  0.0000,  2.0000, 15.7417,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "195 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "196 - tensor([ 3.0000,  1.0000, 29.0000,  2.0000,  0.0000, 21.6792,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "197 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  9.8375,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "198 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "199 - tensor([  1.0000,   1.0000,  27.0000,   0.0000,   2.0000, 211.5000,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "200 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 31.0000,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "201 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "202 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "203 - tensor([ 3.0000,  1.0000,  9.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "204 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000, 22.5250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "205 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "206 - tensor([ 1.0000,  0.0000, 18.0000,  0.0000,  2.0000, 79.6500,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "207 - tensor([ 2.0000,  0.0000, 14.0000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "208 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "209 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "210 - tensor([  1.0000,   0.0000,  18.0000,   1.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "211 - tensor([ 3.0000,  1.0000, 40.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "212 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.5208,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "213 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "214 - tensor([ 1.0000,  1.0000, 45.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "215 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "216 - tensor([ 2.0000,  0.0000,  5.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "217 - tensor([ 3.0000,  1.0000, 16.0000,  2.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "218 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "219 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "220 - tensor([ 1.0000,  0.0000, 53.0000,  2.0000,  0.0000, 51.4792,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "221 - tensor([ 2.0000,  0.0000,  4.0000,  1.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "222 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "223 - tensor([ 3.0000,  1.0000, 41.0000,  2.0000,  0.0000, 14.1083,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "224 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "225 - tensor([ 3.0000,  1.0000,  8.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "226 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  7.0542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "227 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "228 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  3.0000, 18.7500,  2.0000, 21.1792,\n",
      "         3.0000,  5.0000,  0.0000]): 1\n",
      "229 - tensor([ 1.0000,  1.0000, 54.0000,  0.0000,  1.0000, 77.2875,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "230 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "231 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 38.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "232 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "233 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "234 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "235 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "236 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "237 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "238 - tensor([ 3.0000,  0.0000, 45.0000,  0.0000,  1.0000, 14.4542,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "239 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  4.0125,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "240 - tensor([ 3.0000,  0.0000, 14.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "241 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  1.0000,  8.4042,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "242 - tensor([ 2.0000,  1.0000, 24.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "243 - tensor([ 3.0000,  0.0000,  9.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "244 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "245 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "246 - tensor([ 3.0000,  0.0000, 33.0000,  3.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "247 - tensor([ 2.0000,  0.0000, 28.0000,  0.0000,  0.0000, 12.6500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "248 - tensor([ 1.0000,  1.0000, 71.0000,  0.0000,  0.0000, 49.5042,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "249 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "250 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "251 - tensor([ 1.0000,  1.0000, 34.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "252 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "253 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "254 - tensor([ 2.0000,  1.0000, 21.0000,  0.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "255 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "256 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "257 - tensor([ 2.0000,  1.0000, 25.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "258 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "259 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "260 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "261 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "262 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "263 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "264 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  2.0000, 11.1333,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "265 - tensor([ 2.0000,  1.0000,  0.8300,  0.0000,  2.0000, 29.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "266 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "267 - tensor([ 1.0000,  1.0000, 45.5000,  0.0000,  0.0000, 28.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "268 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "269 - tensor([ 2.0000,  0.0000,  8.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "270 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "271 - tensor([ 2.0000,  0.0000, 41.0000,  0.0000,  1.0000, 19.5000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "272 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "273 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  0.0000, 55.9000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "274 - tensor([ 2.0000,  0.0000, 48.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "275 - tensor([ 3.0000,  0.0000, 63.0000,  0.0000,  0.0000,  9.5875,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "276 - tensor([ 3.0000,  1.0000,  9.0000,  0.0000,  2.0000, 20.5250,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "277 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "278 - tensor([  1.0000,   1.0000,  36.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   2.0000,   3.0000,   0.0000]): 1\n",
      "279 - tensor([ 1.0000,  1.0000, 33.0000,  0.0000,  0.0000,  5.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "280 - tensor([ 3.0000,  0.0000, 26.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "281 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8292,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "282 - tensor([  1.0000,   0.0000,  15.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "283 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "284 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "285 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "286 - tensor([ 3.0000,  1.0000,  0.4200,  0.0000,  1.0000,  8.5167,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "287 - tensor([  1.0000,   0.0000,  21.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "288 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.7417,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "289 - tensor([ 1.0000,  0.0000, 33.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "290 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "291 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.3500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "292 - tensor([ 3.0000,  1.0000, 11.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "293 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "294 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 22.3583,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "295 - tensor([ 1.0000,  1.0000, 54.0000,  0.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "296 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "297 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  1.0000, 55.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "298 - tensor([ 1.0000,  0.0000, 47.0000,  1.0000,  1.0000, 52.5542,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "299 - tensor([ 3.0000,  1.0000,  9.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "300 - tensor([ 1.0000,  1.0000, 38.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "301 - tensor([ 1.0000,  1.0000, 61.0000,  0.0000,  0.0000, 32.3208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "302 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "303 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "304 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "305 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "306 - tensor([ 1.0000,  1.0000, 39.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "307 - tensor([ 1.0000,  1.0000, 48.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "308 - tensor([ 2.0000,  1.0000, 42.0000,  1.0000,  0.0000, 27.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "309 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "310 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "311 - tensor([ 2.0000,  0.0000, 36.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "312 - tensor([ 1.0000,  1.0000, 37.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "313 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "314 - tensor([ 2.0000,  0.0000, 57.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "315 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "316 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000,  7.0458,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "317 - tensor([ 3.0000,  0.0000, 24.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "318 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "319 - tensor([ 1.0000,  1.0000, 48.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "320 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "321 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "322 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "323 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.2167,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "324 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "325 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "326 - tensor([ 1.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "327 - tensor([ 3.0000,  0.0000, 11.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "328 - tensor([ 3.0000,  1.0000, 24.0000,  2.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "329 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  8.0292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "330 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  1.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "331 - tensor([ 3.0000,  1.0000, 24.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "332 - tensor([ 3.0000,  1.0000, 28.5000,  0.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "333 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "334 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "335 - tensor([ 2.0000,  0.0000, 24.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "336 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "337 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "338 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "339 - tensor([ 3.0000,  0.0000, 31.0000,  0.0000,  0.0000,  8.6833,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "340 - tensor([ 1.0000,  1.0000, 31.0000,  0.0000,  0.0000, 50.4958,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "341 - tensor([  1.0000,   0.0000,  39.0000,   1.0000,   1.0000, 110.8833,   0.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "342 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "343 - tensor([ 2.0000,  1.0000,  0.6700,  1.0000,  1.0000, 14.5000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "344 - tensor([ 2.0000,  0.0000, 45.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "345 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "346 - tensor([ 3.0000,  1.0000, 40.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "347 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "348 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "349 - tensor([ 2.0000,  1.0000, 47.0000,  0.0000,  0.0000, 15.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "350 - tensor([ 3.0000,  1.0000, 50.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "351 - tensor([ 1.0000,  1.0000, 40.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "352 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "353 - tensor([ 3.0000,  0.0000, 35.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "354 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "355 - tensor([ 3.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "356 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "357 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "358 - tensor([ 1.0000,  1.0000, 32.0000,  0.0000,  0.0000, 30.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "359 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  0.0000, 15.5500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "360 - tensor([ 3.0000,  1.0000, 30.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "361 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "362 - tensor([ 3.0000,  0.0000, 43.0000,  1.0000,  6.0000, 46.9000,  2.0000, 13.3029,\n",
      "         3.0000,  7.0000,  0.0000]): 0\n",
      "363 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "364 - tensor([ 1.0000,  1.0000, 60.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "365 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "366 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 31.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "367 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "368 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "369 - tensor([  1.0000,   0.0000,  24.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "370 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "371 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "372 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "373 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "374 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7875,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "375 - tensor([ 1.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.5500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "376 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "377 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "378 - tensor([ 3.0000,  1.0000, 27.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "379 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "380 - tensor([ 1.0000,  1.0000, 60.0000,  1.0000,  1.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "381 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "382 - tensor([ 2.0000,  1.0000,  1.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "383 - tensor([  1.0000,   0.0000,  38.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "384 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "385 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "386 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "387 - tensor([ 2.0000,  0.0000, 29.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "388 - tensor([ 3.0000,  0.0000,  4.0000,  0.0000,  2.0000, 22.0250,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "389 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "390 - tensor([ 3.0000,  1.0000, 23.5000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "391 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  1.0000, 29.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "392 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "393 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "394 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "395 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  8.6542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "396 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "397 - tensor([ 1.0000,  0.0000, 50.0000,  0.0000,  0.0000, 28.7125,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "398 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "399 - tensor([  1.0000,   0.0000,  18.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "400 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "401 - tensor([ 2.0000,  1.0000, 19.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "402 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "403 - tensor([ 2.0000,  1.0000, 57.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "404 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "405 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 42.4000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "406 - tensor([ 2.0000,  1.0000, 24.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "407 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "408 - tensor([  1.0000,   1.0000,  36.0000,   0.0000,   1.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 1\n",
      "409 - tensor([ 3.0000,  0.0000, 18.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "410 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "411 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "412 - tensor([ 2.0000,  1.0000, 60.0000,  1.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "413 - tensor([ 2.0000,  0.0000, 18.0000,  0.0000,  2.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "414 - tensor([ 2.0000,  1.0000, 33.0000,  0.0000,  0.0000, 12.2750,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "415 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  9.2250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "416 - tensor([ 2.0000,  0.0000, 32.5000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "417 - tensor([ 1.0000,  1.0000, 37.0000,  1.0000,  1.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "418 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "419 - tensor([  1.0000,   1.0000,   0.9200,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "420 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "421 - tensor([ 3.0000,  0.0000, 20.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "422 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "423 - tensor([ 2.0000,  0.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "424 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "425 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   3.0000,   3.0000,   0.0000]): 1\n",
      "426 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  1.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "427 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "428 - tensor([ 3.0000,  0.0000, 17.0000,  4.0000,  2.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 1\n",
      "429 - tensor([ 2.0000,  0.0000, 21.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "430 - tensor([ 3.0000,  0.0000,  2.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         1.0000,  5.0000,  0.0000]): 0\n",
      "431 - tensor([ 1.0000,  0.0000, 38.0000,  1.0000,  0.0000, 71.2833,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "432 - tensor([ 2.0000,  0.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "433 - tensor([ 3.0000,  0.0000, 25.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "434 - tensor([ 3.0000,  0.0000, 19.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "435 - tensor([ 1.0000,  1.0000, 70.0000,  1.0000,  1.0000, 71.0000,  2.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "436 - tensor([ 2.0000,  0.0000, 40.0000,  1.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "437 - tensor([ 2.0000,  1.0000, 59.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "438 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "439 - tensor([ 1.0000,  0.0000, 49.0000,  0.0000,  0.0000, 25.9292,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "440 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 12.8750,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "441 - tensor([ 3.0000,  0.0000,  5.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "442 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "443 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "444 - tensor([ 2.0000,  0.0000, 29.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "445 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "446 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "447 - tensor([ 2.0000,  1.0000,  1.0000,  0.0000,  2.0000, 37.0042,  0.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "448 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 39.4000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "449 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "450 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "451 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "452 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "453 - tensor([ 1.0000,  1.0000, 29.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "454 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "455 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "456 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "457 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "458 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "459 - tensor([ 1.0000,  1.0000, 62.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "460 - tensor([ 1.0000,  1.0000, 28.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "461 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "462 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "463 - tensor([ 2.0000,  0.0000, 26.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "464 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "465 - tensor([  1.0000,   0.0000,  40.0000,   1.0000,   1.0000, 134.5000,   0.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "466 - tensor([ 1.0000,  0.0000, 60.0000,  1.0000,  0.0000, 75.2500,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "467 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "468 - tensor([ 3.0000,  0.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "469 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "470 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "471 - tensor([ 3.0000,  0.0000, 10.0000,  0.0000,  2.0000, 24.1500,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "472 - tensor([ 1.0000,  0.0000, 56.0000,  0.0000,  1.0000, 83.1583,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "473 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 33.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "474 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.3125,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "475 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  2.0000, 16.7000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "476 - tensor([ 3.0000,  0.0000, 15.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "477 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "478 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "479 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "480 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "481 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "482 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "483 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "484 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "485 - tensor([ 1.0000,  1.0000, 55.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "486 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "487 - tensor([ 2.0000,  1.0000, 50.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "488 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "489 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "490 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "491 - tensor([ 1.0000,  0.0000, 62.0000,  0.0000,  0.0000, 80.0000,  3.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "492 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "493 - tensor([ 3.0000,  0.0000,  8.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "494 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "495 - tensor([ 2.0000,  0.0000, 25.0000,  0.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "496 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "497 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "498 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 47.1000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "499 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  8.6625,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "500 - tensor([ 1.0000,  0.0000, 49.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "501 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "502 - tensor([ 3.0000,  1.0000, 28.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "503 - tensor([  1.0000,   1.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 1\n",
      "504 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  1.0000, 20.5250,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "505 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "506 - tensor([ 3.0000,  0.0000, 30.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "507 - tensor([ 2.0000,  0.0000,  7.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "508 - tensor([ 3.0000,  1.0000, 24.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "509 - tensor([ 2.0000,  1.0000,  0.8300,  1.0000,  1.0000, 18.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "510 - tensor([ 3.0000,  1.0000, 40.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "511 - tensor([ 1.0000,  1.0000, 51.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "512 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 135.6333,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "513 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "514 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "515 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "516 - tensor([  1.0000,   1.0000,  64.0000,   1.0000,   4.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "517 - tensor([ 3.0000,  1.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         2.0000,  6.0000,  0.0000]): 0\n",
      "518 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "519 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "520 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "521 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "522 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "523 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "524 - tensor([ 2.0000,  0.0000, 33.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "525 - tensor([ 3.0000,  0.0000, 45.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "526 - tensor([ 3.0000,  0.0000, 40.0000,  1.0000,  0.0000,  9.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "527 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  0.0000,  8.8500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "528 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "529 - tensor([ 3.0000,  1.0000, 47.0000,  0.0000,  0.0000,  9.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "530 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "531 - tensor([ 2.0000,  0.0000,  4.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "532 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 13.8583,  0.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "533 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "534 - tensor([ 3.0000,  1.0000, 10.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "535 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "536 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "537 - tensor([  1.0000,   0.0000,  17.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "538 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "539 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "540 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "541 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  6.4500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "542 - tensor([  1.0000,   0.0000,  31.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "543 - tensor([ 1.0000,  1.0000, 37.0000,  0.0000,  1.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "544 - tensor([ 3.0000,  1.0000,  6.0000,  0.0000,  1.0000, 12.4750,  2.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "545 - tensor([  1.0000,   0.0000,  23.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "546 - tensor([ 1.0000,  1.0000, 62.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "547 - tensor([ 1.0000,  1.0000, 46.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "548 - tensor([ 3.0000,  1.0000, 29.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "549 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "550 - tensor([ 3.0000,  0.0000, 38.0000,  1.0000,  5.0000, 31.3875,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 1\n",
      "551 - tensor([ 3.0000,  0.0000,  5.0000,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "552 - tensor([ 3.0000,  0.0000, 30.0000,  1.0000,  1.0000, 24.1500,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "553 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  2.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "554 - tensor([ 2.0000,  1.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "555 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "556 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "557 - tensor([ 1.0000,  1.0000, 42.0000,  1.0000,  0.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "558 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "559 - tensor([ 2.0000,  1.0000,  3.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "560 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 37.0042,  0.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "561 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "562 - tensor([  1.0000,   1.0000,  18.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "563 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "564 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "565 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.4583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "566 - tensor([ 3.0000,  1.0000, 49.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "567 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "568 - tensor([ 2.0000,  1.0000, 70.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "569 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.4333,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "570 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "571 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "572 - tensor([ 3.0000,  1.0000,  3.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 1\n",
      "573 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.6292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "574 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "575 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "576 - tensor([  1.0000,   0.0000,  43.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "577 - tensor([  1.0000,   0.0000,  23.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "578 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "579 - tensor([ 1.0000,  0.0000, 63.0000,  1.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "580 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "581 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "582 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "583 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "584 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "585 - tensor([ 3.0000,  1.0000, 37.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "586 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "587 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "588 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 12.0000,  0.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "589 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "590 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "591 - tensor([  1.0000,   0.0000,  45.0000,   1.0000,   1.0000, 164.8667,   2.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "592 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "593 - tensor([ 2.0000,  1.0000, 32.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "594 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "595 - tensor([ 2.0000,  1.0000, 32.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "596 - tensor([ 2.0000,  0.0000, 35.0000,  0.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "597 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "598 - tensor([ 3.0000,  1.0000, 15.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "599 - tensor([ 2.0000,  1.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "600 - tensor([ 1.0000,  0.0000, 17.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "601 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  2.0000, 14.5000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "602 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 25.5875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "603 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "604 - tensor([ 3.0000,  1.0000, 45.5000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "605 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "606 - tensor([ 2.0000,  1.0000, 21.0000,  1.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "607 - tensor([ 2.0000,  1.0000, 36.5000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "608 - tensor([ 3.0000,  1.0000, 28.5000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "609 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.1375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "610 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "611 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "612 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 14.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "613 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "614 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "615 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "616 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.0500,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "617 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.1583,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "618 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  0.0000,  7.0542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "619 - tensor([ 3.0000,  1.0000, 20.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "620 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "621 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   1.0000, 153.4625,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "622 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "623 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "624 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "625 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "626 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "627 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "628 - tensor([ 2.0000,  1.0000, 66.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "629 - tensor([ 1.0000,  1.0000, 46.0000,  1.0000,  0.0000, 61.1750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "630 - tensor([ 1.0000,  1.0000, 19.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "631 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "632 - tensor([  1.0000,   0.0000,  50.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "633 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "634 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000, 10.5167,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "635 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "636 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "637 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 49.5042,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "638 - tensor([ 3.0000,  1.0000, 48.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "639 - tensor([ 3.0000,  0.0000,  0.7500,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "640 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 69.3000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "641 - tensor([ 3.0000,  0.0000, 13.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "642 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "643 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  2.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "644 - tensor([ 2.0000,  0.0000, 34.0000,  1.0000,  1.0000, 32.5000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "645 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "646 - tensor([ 1.0000,  1.0000, 64.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "647 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "648 - tensor([ 3.0000,  0.0000, 29.0000,  1.0000,  1.0000, 10.4625,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "649 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 50.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "650 - tensor([ 3.0000,  1.0000, 16.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "651 - tensor([ 3.0000,  1.0000, 16.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "652 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "653 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "654 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "655 - tensor([ 3.0000,  1.0000,  2.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         0.0000,  4.0000,  0.0000]): 0\n",
      "656 - tensor([ 1.0000,  0.0000, 32.0000,  0.0000,  0.0000, 76.2917,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "657 - tensor([ 3.0000,  0.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "658 - tensor([ 3.0000,  0.0000, 41.0000,  0.0000,  5.0000, 39.6875,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "659 - tensor([ 3.0000,  0.0000, 19.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "660 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "661 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "662 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "663 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "664 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "665 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "666 - tensor([ 3.0000,  0.0000, 16.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         1.0000,  7.0000,  0.0000]): 0\n",
      "667 - tensor([ 3.0000,  0.0000, 18.0000,  2.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "668 - tensor([ 3.0000,  0.0000, 22.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "669 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "670 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "671 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "672 - tensor([  1.0000,   0.0000,  29.0000,   0.0000,   0.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "673 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 25.9250,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "674 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "675 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "676 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "677 - tensor([ 1.0000,  1.0000, 52.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "678 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "679 - tensor([ 1.0000,  1.0000, 24.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "680 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "681 - tensor([ 1.0000,  1.0000, 40.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "682 - tensor([ 3.0000,  1.0000,  1.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "683 - tensor([  1.0000,   0.0000,  36.0000,   0.0000,   0.0000, 135.6333,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "684 - tensor([ 2.0000,  0.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "685 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "686 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "687 - tensor([ 2.0000,  1.0000,  8.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "688 - tensor([  1.0000,   1.0000,  19.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "689 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "690 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "691 - tensor([ 3.0000,  1.0000, 55.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "692 - tensor([ 1.0000,  1.0000, 51.0000,  0.0000,  1.0000, 61.3792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "693 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "694 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "695 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "696 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  9.8417,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "697 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "698 - tensor([ 1.0000,  1.0000, 48.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "699 - tensor([  1.0000,   0.0000,  41.0000,   0.0000,   0.0000, 134.5000,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "700 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "701 - tensor([ 1.0000,  1.0000, 23.0000,  0.0000,  1.0000, 63.3583,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "702 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "703 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "704 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "705 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "706 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "707 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "708 - tensor([ 1.0000,  1.0000, 52.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "709 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "710 - tensor([ 2.0000,  1.0000, 51.0000,  0.0000,  0.0000, 12.5250,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "711 - tensor([ 2.0000,  0.0000, 28.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "712 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "################################################## 2\n",
      "[TRAIN]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([16, 11]): torch.Size([16])\n",
      "12 - torch.Size([16, 11]): torch.Size([16])\n",
      "13 - torch.Size([16, 11]): torch.Size([16])\n",
      "14 - torch.Size([16, 11]): torch.Size([16])\n",
      "15 - torch.Size([16, 11]): torch.Size([16])\n",
      "16 - torch.Size([16, 11]): torch.Size([16])\n",
      "17 - torch.Size([16, 11]): torch.Size([16])\n",
      "18 - torch.Size([16, 11]): torch.Size([16])\n",
      "19 - torch.Size([16, 11]): torch.Size([16])\n",
      "20 - torch.Size([16, 11]): torch.Size([16])\n",
      "21 - torch.Size([16, 11]): torch.Size([16])\n",
      "22 - torch.Size([16, 11]): torch.Size([16])\n",
      "23 - torch.Size([16, 11]): torch.Size([16])\n",
      "24 - torch.Size([16, 11]): torch.Size([16])\n",
      "25 - torch.Size([16, 11]): torch.Size([16])\n",
      "26 - torch.Size([16, 11]): torch.Size([16])\n",
      "27 - torch.Size([16, 11]): torch.Size([16])\n",
      "28 - torch.Size([16, 11]): torch.Size([16])\n",
      "29 - torch.Size([16, 11]): torch.Size([16])\n",
      "30 - torch.Size([16, 11]): torch.Size([16])\n",
      "31 - torch.Size([16, 11]): torch.Size([16])\n",
      "32 - torch.Size([16, 11]): torch.Size([16])\n",
      "33 - torch.Size([16, 11]): torch.Size([16])\n",
      "34 - torch.Size([16, 11]): torch.Size([16])\n",
      "35 - torch.Size([16, 11]): torch.Size([16])\n",
      "36 - torch.Size([16, 11]): torch.Size([16])\n",
      "37 - torch.Size([16, 11]): torch.Size([16])\n",
      "38 - torch.Size([16, 11]): torch.Size([16])\n",
      "39 - torch.Size([16, 11]): torch.Size([16])\n",
      "40 - torch.Size([16, 11]): torch.Size([16])\n",
      "41 - torch.Size([16, 11]): torch.Size([16])\n",
      "42 - torch.Size([16, 11]): torch.Size([16])\n",
      "43 - torch.Size([16, 11]): torch.Size([16])\n",
      "44 - torch.Size([9, 11]): torch.Size([9])\n",
      "[VALIDATION]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([2, 11]): torch.Size([2])\n",
      "################################################## 3\n",
      "[TEST]\n",
      "torch.Size([418, 11])\n",
      "892 1\n",
      "893 1\n",
      "894 1\n",
      "895 1\n",
      "896 0\n",
      "897 0\n",
      "898 1\n",
      "899 0\n",
      "900 0\n",
      "901 0\n",
      "902 1\n",
      "903 0\n",
      "904 0\n",
      "905 1\n",
      "906 0\n",
      "907 0\n",
      "908 0\n",
      "909 0\n",
      "910 1\n",
      "911 1\n",
      "912 0\n",
      "913 0\n",
      "914 0\n",
      "915 0\n",
      "916 0\n",
      "917 1\n",
      "918 0\n",
      "919 0\n",
      "920 0\n",
      "921 0\n",
      "922 0\n",
      "923 0\n",
      "924 0\n",
      "925 0\n",
      "926 0\n",
      "927 0\n",
      "928 0\n",
      "929 0\n",
      "930 0\n",
      "931 0\n",
      "932 1\n",
      "933 0\n",
      "934 1\n",
      "935 0\n",
      "936 0\n",
      "937 1\n",
      "938 0\n",
      "939 1\n",
      "940 0\n",
      "941 1\n",
      "942 0\n",
      "943 0\n",
      "944 0\n",
      "945 0\n",
      "946 0\n",
      "947 0\n",
      "948 1\n",
      "949 1\n",
      "950 0\n",
      "951 0\n",
      "952 0\n",
      "953 0\n",
      "954 0\n",
      "955 0\n",
      "956 0\n",
      "957 0\n",
      "958 0\n",
      "959 0\n",
      "960 0\n",
      "961 0\n",
      "962 0\n",
      "963 0\n",
      "964 1\n",
      "965 0\n",
      "966 0\n",
      "967 0\n",
      "968 1\n",
      "969 0\n",
      "970 0\n",
      "971 0\n",
      "972 0\n",
      "973 0\n",
      "974 0\n",
      "975 1\n",
      "976 0\n",
      "977 0\n",
      "978 0\n",
      "979 0\n",
      "980 1\n",
      "981 0\n",
      "982 0\n",
      "983 1\n",
      "984 0\n",
      "985 1\n",
      "986 0\n",
      "987 1\n",
      "988 0\n",
      "989 1\n",
      "990 0\n",
      "991 1\n",
      "992 0\n",
      "993 0\n",
      "994 1\n",
      "995 1\n",
      "996 0\n",
      "997 0\n",
      "998 0\n",
      "999 1\n",
      "1000 1\n",
      "1001 0\n",
      "1002 0\n",
      "1003 0\n",
      "1004 0\n",
      "1005 0\n",
      "1006 0\n",
      "1007 0\n",
      "1008 1\n",
      "1009 0\n",
      "1010 0\n",
      "1011 0\n",
      "1012 0\n",
      "1013 1\n",
      "1014 0\n",
      "1015 1\n",
      "1016 1\n",
      "1017 0\n",
      "1018 0\n",
      "1019 0\n",
      "1020 0\n",
      "1021 0\n",
      "1022 1\n",
      "1023 0\n",
      "1024 0\n",
      "1025 1\n",
      "1026 1\n",
      "1027 1\n",
      "1028 1\n",
      "1029 0\n",
      "1030 0\n",
      "1031 0\n",
      "1032 0\n",
      "1033 0\n",
      "1034 0\n",
      "1035 0\n",
      "1036 0\n",
      "1037 1\n",
      "1038 0\n",
      "1039 0\n",
      "1040 0\n",
      "1041 0\n",
      "1042 0\n",
      "1043 1\n",
      "1044 1\n",
      "1045 1\n",
      "1046 0\n",
      "1047 1\n",
      "1048 0\n",
      "1049 0\n",
      "1050 0\n",
      "1051 0\n",
      "1052 0\n",
      "1053 0\n",
      "1054 0\n",
      "1055 1\n",
      "1056 0\n",
      "1057 0\n",
      "1058 0\n",
      "1059 0\n",
      "1060 0\n",
      "1061 0\n",
      "1062 1\n",
      "1063 1\n",
      "1064 0\n",
      "1065 1\n",
      "1066 0\n",
      "1067 0\n",
      "1068 0\n",
      "1069 0\n",
      "1070 0\n",
      "1071 0\n",
      "1072 0\n",
      "1073 0\n",
      "1074 0\n",
      "1075 1\n",
      "1076 0\n",
      "1077 0\n",
      "1078 0\n",
      "1079 0\n",
      "1080 0\n",
      "1081 0\n",
      "1082 0\n",
      "1083 0\n",
      "1084 0\n",
      "1085 1\n",
      "1086 0\n",
      "1087 1\n",
      "1088 0\n",
      "1089 0\n",
      "1090 0\n",
      "1091 1\n",
      "1092 0\n",
      "1093 0\n",
      "1094 0\n",
      "1095 0\n",
      "1096 0\n",
      "1097 0\n",
      "1098 1\n",
      "1099 0\n",
      "1100 0\n",
      "1101 1\n",
      "1102 0\n",
      "1103 1\n",
      "1104 0\n",
      "1105 0\n",
      "1106 1\n",
      "1107 0\n",
      "1108 0\n",
      "1109 0\n",
      "1110 0\n",
      "1111 1\n",
      "1112 0\n",
      "1113 0\n",
      "1114 0\n",
      "1115 0\n",
      "1116 0\n",
      "1117 1\n",
      "1118 0\n",
      "1119 0\n",
      "1120 1\n",
      "1121 0\n",
      "1122 0\n",
      "1123 0\n",
      "1124 0\n",
      "1125 1\n",
      "1126 0\n",
      "1127 0\n",
      "1128 0\n",
      "1129 0\n",
      "1130 0\n",
      "1131 0\n",
      "1132 0\n",
      "1133 0\n",
      "1134 0\n",
      "1135 1\n",
      "1136 0\n",
      "1137 0\n",
      "1138 0\n",
      "1139 0\n",
      "1140 0\n",
      "1141 1\n",
      "1142 0\n",
      "1143 0\n",
      "1144 0\n",
      "1145 0\n",
      "1146 1\n",
      "1147 1\n",
      "1148 1\n",
      "1149 1\n",
      "1150 0\n",
      "1151 0\n",
      "1152 1\n",
      "1153 0\n",
      "1154 0\n",
      "1155 0\n",
      "1156 0\n",
      "1157 1\n",
      "1158 0\n",
      "1159 1\n",
      "1160 0\n",
      "1161 0\n",
      "1162 0\n",
      "1163 1\n",
      "1164 0\n",
      "1165 0\n",
      "1166 1\n",
      "1167 0\n",
      "1168 0\n",
      "1169 0\n",
      "1170 0\n",
      "1171 0\n",
      "1172 0\n",
      "1173 0\n",
      "1174 0\n",
      "1175 0\n",
      "1176 0\n",
      "1177 1\n",
      "1178 1\n",
      "1179 0\n",
      "1180 1\n",
      "1181 1\n",
      "1182 0\n",
      "1183 1\n",
      "1184 1\n",
      "1185 0\n",
      "1186 1\n",
      "1187 1\n",
      "1188 0\n",
      "1189 0\n",
      "1190 0\n",
      "1191 1\n",
      "1192 1\n",
      "1193 0\n",
      "1194 0\n",
      "1195 0\n",
      "1196 0\n",
      "1197 0\n",
      "1198 0\n",
      "1199 0\n",
      "1200 0\n",
      "1201 1\n",
      "1202 0\n",
      "1203 0\n",
      "1204 1\n",
      "1205 1\n",
      "1206 0\n",
      "1207 0\n",
      "1208 0\n",
      "1209 0\n",
      "1210 1\n",
      "1211 0\n",
      "1212 1\n",
      "1213 0\n",
      "1214 0\n",
      "1215 0\n",
      "1216 0\n",
      "1217 0\n",
      "1218 0\n",
      "1219 0\n",
      "1220 0\n",
      "1221 0\n",
      "1222 0\n",
      "1223 0\n",
      "1224 1\n",
      "1225 0\n",
      "1226 1\n",
      "1227 0\n",
      "1228 0\n",
      "1229 1\n",
      "1230 0\n",
      "1231 0\n",
      "1232 0\n",
      "1233 1\n",
      "1234 0\n",
      "1235 0\n",
      "1236 0\n",
      "1237 0\n",
      "1238 0\n",
      "1239 1\n",
      "1240 0\n",
      "1241 0\n",
      "1242 0\n",
      "1243 0\n",
      "1244 0\n",
      "1245 0\n",
      "1246 0\n",
      "1247 0\n",
      "1248 0\n",
      "1249 1\n",
      "1250 1\n",
      "1251 1\n",
      "1252 0\n",
      "1253 0\n",
      "1254 0\n",
      "1255 1\n",
      "1256 0\n",
      "1257 0\n",
      "1258 0\n",
      "1259 0\n",
      "1260 0\n",
      "1261 0\n",
      "1262 0\n",
      "1263 0\n",
      "1264 0\n",
      "1265 0\n",
      "1266 0\n",
      "1267 0\n",
      "1268 0\n",
      "1269 0\n",
      "1270 0\n",
      "1271 0\n",
      "1272 1\n",
      "1273 1\n",
      "1274 1\n",
      "1275 0\n",
      "1276 0\n",
      "1277 0\n",
      "1278 1\n",
      "1279 1\n",
      "1280 0\n",
      "1281 0\n",
      "1282 0\n",
      "1283 0\n",
      "1284 0\n",
      "1285 1\n",
      "1286 0\n",
      "1287 0\n",
      "1288 0\n",
      "1289 0\n",
      "1290 0\n",
      "1291 1\n",
      "1292 0\n",
      "1293 0\n",
      "1294 0\n",
      "1295 0\n",
      "1296 0\n",
      "1297 0\n",
      "1298 0\n",
      "1299 0\n",
      "1300 0\n",
      "1301 0\n",
      "1302 0\n",
      "1303 0\n",
      "1304 1\n",
      "1305 1\n",
      "1306 0\n",
      "1307 1\n",
      "1308 1\n",
      "1309 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  ## 전처리된 데이터셋 불러옴\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "  ## 각 데이터셋의 크기 출력, 데이터셋이 잘 분할되었는지 확인\n",
    "  print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "    len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "  ))\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  ## 훈련 데이터셋에서 각 샘플의 인덱스와 입력 데이터('input'), 타겟 데이터('target') 출력\n",
    "  for idx, sample in enumerate(train_dataset):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, sample['input'], sample['target']))\n",
    "\n",
    "  print(\"#\" * 50, 2)\n",
    "\n",
    "  ## 훈련, 검증 데이터는 배치 크기 16으로 설정하고 순서를 섞음\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=16, shuffle=True)\n",
    "  ## 테스트 데이터는 테스트 데이터셋 전체를 한 번에 처리하도록 설정\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  print(\"[TRAIN]\")\n",
    "  ## 훈련 데이터의 각 배치마다 입력 데이터와 타겟 데이터의 모양을 출력\n",
    "  for idx, batch in enumerate(train_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"[VALIDATION]\")\n",
    "  ## 검증 데이터의 각 배치마다 입력 데이터와 타겟 데이터의 모양을 출력\n",
    "  for idx, batch in enumerate(validation_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"#\" * 50, 3)\n",
    "\n",
    "  ## test 함수에서 테스트 데이터셋을 모델에 입력하여 예측값 출력\n",
    "  test(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c43912b09948f",
   "metadata": {},
   "source": [
    "- 전처리된 데이터셋을 불러오고, 훈련, 검증, 테스트 데이터셋을 생성한 후 각각의 데이터셋을 로더에 담아 학습 및 예측 과정을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bd607baaa3925",
   "metadata": {},
   "source": [
    "- FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
    "- 위와 같은 에러가 발생했었는데, 이 에러는 pandas 라이브러리에서 DataFrame이나 Series를 복사본에 대해 값을 수정하려고 할 때 발생하는 경고라고 한다. pandas 3.0에서는 inplace = True 방식이 더 이상 제대로 동작하지 않기 때문에 코드를 수정하였다.\n",
    "\n",
    "- NameError: name '\\_\\_file\\_\\_' is not defined\n",
    "- 위와 같은 에러도 발생했었는데, Jupyter Notebook에서는 \\_\\_file\\_\\_ 변수가 정의되지 않기 때문에 현재 작업 디렉토리를 사용할 수 있도록 os.getcwd()를 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a661bf6e02586a",
   "metadata": {},
   "source": [
    "# **요구사항 2: titanic 딥러닝 모델 훈련 코드 및 Activation Function 변경해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "228d90b389049974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:27:51.863851Z",
     "start_time": "2024-10-24T16:27:27.951615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\git\\link_dl !!!!!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\user\\git\\link_dl\\_03_your_code\\hw2\\wandb\\run-20241025_012727-ic4nten6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/ic4nten6' target=\"_blank\">2024-10-25_01-27-27</a></strong> to <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/ic4nten6' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/ic4nten6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=False, batch_size=256, epochs=1000)\n",
      "{'epochs': 1000, 'batch_size': 256, 'learning_rate': 0.001, 'n_hidden_unit_list': [30, 30, 30]}\n",
      "Data Size: 891, Input Shape: torch.Size([891, 11]), Target Shape: torch.Size([891])\n",
      "713 178\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.6958, Validation loss 0.6954\n",
      "Epoch 200, Training loss 0.6540, Validation loss 0.6587\n",
      "Epoch 300, Training loss 0.6402, Validation loss 0.6730\n",
      "Epoch 400, Training loss 0.6355, Validation loss 0.6586\n",
      "Epoch 500, Training loss 0.6517, Validation loss 0.6323\n",
      "Epoch 600, Training loss 0.6284, Validation loss 0.6238\n",
      "Epoch 700, Training loss 0.6267, Validation loss 0.6283\n",
      "Epoch 800, Training loss 0.6266, Validation loss 0.6243\n",
      "Epoch 900, Training loss 0.6289, Validation loss 0.5728\n",
      "Epoch 1000, Training loss 0.6080, Validation loss 0.6035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>Training loss</td><td>██▅▆▅▃▃▃▂▂▃▃▂▃▂▂▃▂▂▂▂▁▂▁▂▁▁▂▃▂▂▁▁▂▂▂▂▁▁▁</td></tr><tr><td>Validation loss</td><td>▆█▇▆▅▃▄▄▃▆▃▅▃▂▂▃▄▄▂▂▃▃▄▃▁▂▄▃▂▂▂▄▃▃▂▃▂▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.60799</td></tr><tr><td>Validation loss</td><td>0.60347</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-25_01-27-27</strong> at: <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/ic4nten6' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/ic4nten6</a><br/> View project at: <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241025_012727-ic4nten6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "BASE_PATH = str(Path(os.getcwd()).resolve().parent.parent)\n",
    "\n",
    "##BASE_PATH = str(Path(__file__).resolve().parent.parent) # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "print(BASE_PATH, \"!!!!!!!\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_your_code.hw2.titanic_dataset import TitanicDataset\n",
    "from _03_your_code.hw2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "def get_data():\n",
    "  train_X, train_y, test_X = get_preprocessed_dataset() ## 전처리된 데이터셋 가져오기\n",
    "\n",
    "\n",
    "\n",
    "  # Create a training dataset using TitanicDataset class\n",
    "  dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "  print(dataset)\n",
    "\n",
    "  train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "  print(len(train_dataset), len(validation_dataset))\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "\n",
    "  return train_data_loader, validation_data_loader\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = nn.Sequential( ##활성화 함수 수정해보기\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Dropout(0.4), ## 드롭아웃\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Dropout(0.4), ## 드롭아웃\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], wandb.config.n_hidden_unit_list[2]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[2], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=11, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate) ##Gradient Descent \n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()  # Use a built-in loss function ##loss 함수 정의\n",
    "\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0 ## train loss와 num_trains는 루프마다 초기화 필수\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input = train_batch['input']\n",
    "      target = train_batch['target']\n",
    "      #input, target = train_batch\n",
    "      output_train = model(input) ## 모델 출력\n",
    "      loss = loss_fn(output_train, target) \n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad() ## 그래디언트 초기화\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "## validation loss와 num_validations 초기화 필수\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad(): ## 검증땐 그래디언트 계산 안함\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input = validation_batch['input']\n",
    "        target = validation_batch['target']\n",
    "        #input, target = validation_batch\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    wandb.log({ ## wandb에 로그 기록\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": loss_train / num_trains,\n",
    "      \"Validation loss\": loss_validation / num_validations\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch: ## 특정 에포크마다 출력\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "        f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "\n",
    "def main(args):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_hidden_unit_list': [30, 30, 30],\n",
    "  }\n",
    "\n",
    "  wandb.init( ## wandb 초기화\n",
    "    mode=\"online\",\n",
    "    project=\"titanic_training\",\n",
    "    notes=\"titanic wandb experiment\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=current_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader = get_data() ## 데이터 로더 가져오기\n",
    "\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer() ## 모델 및 옵티마이저 가져오기\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish() ## wandb 종료\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "  ## Jupyter 노트북에서 실행될 경우 필요한 코드\n",
    "  if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]\n",
    "      \n",
    "  ##argumentParser 초기화\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=False, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=256, help=\"Batch size (int, default: 256)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=1_000, help=\"Number of training epochs (int, default:1_000)\"\n",
    "  )\n",
    "\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  main(args) ## 메인 함수 실행\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432139c0e5188a75",
   "metadata": {},
   "source": [
    "- 위 코드는 d_my_model_training_with_argparse_wandb.py 파일을 활용하여 titanic_dataset과 연결되도록 만든 코드이다. \n",
    "- get_preprocessed_dataset 함수를 통해 훈련 및 검증 데이터를 가져온다.\n",
    "- MyModel 클래스에서 신경망 모델을 정의하고, 레이어와 활성화 함수를 설정한다.\n",
    "- 하이퍼파라미터를 설정하고, 이를 사용하여 모델을 훈련시키고 training loss, validation loss를 계산한다.\n",
    "- 위 결과물을 wandb 상에 기록하여 시각화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2879187d9330082",
   "metadata": {},
   "source": [
    "\n",
    "- 활성화 함수 ELU, ReLU, PReLU, LeakyReLU를 사용하여 테스트를 해본 결과 큰 차이는 없지만 LeakyReLU가 가장 낮은 loss를 얻어냈다. 따라서 아래 문제에서도 LeakyReLU를 사용할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc1cd1b505391b",
   "metadata": {},
   "source": [
    "- 아래 3번 문제를 풀기 위해 최대한 loss를 줄이는 방법에 대해 많은 노력을 해봤다. layer의 개수, 뉴런 수, 활성화 함수, 하이퍼파라미터 등을 조정하는 방법도 있지만, Dropout과 BatchNorm1d과 같은 함수들도 있다는 것을 알게 됐다. 아래는 이 함수들에 대한 정보를 정리해보았다.\n",
    "- BatchNorm1d: 배치정규화는 딥러닝 모델의 학습 속도를 높이고, 불안정한 학습을 안정화하기 위해 사용된다. 이를 통해 모델이 더 높은 학습률로 빠르게 수렴할 수 있으며 가중치 초기화에 덜 민감해진다. 배치 정규화는 각 배치에 대해 입력의 평균과 표준편차를 계산하여 입력데이터를 정규화하는 것이다. 특정 층의 입력값들이 학습할때 너무 크거나 작지 않도록 조정하는 역할을 한다. 이 함수를 사용하면 학습이 좀 더 안정화되고, 안정적인 학습이 가능하므로 학습 속도가 증가하고, 정규화 효과를 통해 과적합을 방지하는 데 도움이 될 수 있다.\n",
    "- Dropout: 과적합을 방지하기 위한 정규화 기법이다. 학습 중에 임의로 일부 뉴런을 비활성화시켜서 모델이 특정 뉴런에 과도하게 의존하지 않도록 한다. 이를 통해 모델을 더 일반화할 수 있다. 예를 들어 Dropout(0.5)로 설정하면 학습 중에 절반의 뉴런이 임의로 비활성화된다. 따라서 특정 뉴런에 과도하게 의존하는 것을 방지하고 신경망의 가중치가 더 고르게 학습되도록 돕기 때문에 과적합을 방지할 수 있고, 뉴런을 랜덤하게 제거함으로써 모델이 더 일반화된 성능을 발휘할 수 있다.\n",
    "- CrossEntropyLoss 사용 이유: 원래 이진 분류 문제는 BCEWithLogitsLoss를 사용해야 한다. 찾아보니 BCEWithLogitsLoss는 1일 확률을 구한다면, 0의 확률은 (1 - (1일 확률))인데 CrossEntropyLoss를 사용하면 0일 확률과 1일 확률을 각각 구해서 조금 더 정확도 높은 결과를 얻을 수 있다고 해서 CrossEntropyLoss를 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4888027cf2567f0",
   "metadata": {},
   "source": [
    "- 그리고 3번 문제의 첫번째 코드는 early stopping이 있는 코드이고, 두번째 코드는 early stopping이 없는 코드이다. \n",
    "- 이 둘을 모두 3번에 넣어놓은 이유는 아래와 같다.\n",
    "- 강의 시간에 배울 때는 patience를 10번 정도로 배웠던 것 같은데, 어떤 이유에서인지 100, 200 정도로 넣어도 early stopping 되어 나온 submission 값을 kaggle에 제출하면 0.5~0.6 정도로 너무 점수가 낮게 나온다. \n",
    "- 그리고 train loss와 validation loss 결과에서 train loss는 당연히 계속 내려가지만, validation loss는 다시 상승하게 된다. 이를 막기 위해 early stopping을 걸고 submission을 얻어냈던 것인데, 과적합되어 validation loss 값이 train loss 값보다 유의미하게 높은 때의 submmission을 써야 높은 정확도가 나왔다.\n",
    "- 이 점이 이해가 되지 않아 두 코드 모두 작성해두었다. \n",
    "- 두 번째 코드에서 4000 에포크정도로 학습을 진행하고 submission을 kaggle에 제출하면 0.7~0.75 사이의 점수가 나온다.\n",
    "- 두 번째 코드에서 10,000 에포크로 학습을 진행하면 과적합된 결과가 나오지만, submission 결과는 0.77 정도의 점수가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b9967bf72bd9b",
   "metadata": {},
   "source": [
    "# **요구사항 3: 테스트 및 submission.csv 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82bc283e88a417ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T15:15:32.389532Z",
     "start_time": "2024-10-24T15:15:03.310569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\user\\git\\link_dl\\_03_your_code\\hw2\\wandb\\run-20241025_001503-v3izceum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/v3izceum' target=\"_blank\">2024-10-25_00-15-03</a></strong> to <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/v3izceum' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/v3izceum</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=False, batch_size=256, epochs=10000)\n",
      "{'epochs': 10000, 'batch_size': 256, 'learning_rate': 0.001, 'n_hidden_unit_list': [128, 64, 32]}\n",
      "713 178 418\n",
      "Epoch 100, Training loss 0.6211, Validation loss 0.6597\n",
      "Epoch 200, Training loss 0.6008, Validation loss 0.6567\n",
      "Epoch 300, Training loss 0.5740, Validation loss 0.6298\n",
      "Epoch 400, Training loss 0.5686, Validation loss 0.6241\n",
      "Epoch 500, Training loss 0.5592, Validation loss 0.6111\n",
      "Epoch 600, Training loss 0.5312, Validation loss 0.5893\n",
      "Epoch 700, Training loss 0.5174, Validation loss 0.5721\n",
      "Epoch 800, Training loss 0.5030, Validation loss 0.6046\n",
      "Epoch 900, Training loss 0.5006, Validation loss 0.5674\n",
      "Epoch 1000, Training loss 0.4815, Validation loss 0.5844\n",
      "Epoch 1100, Training loss 0.4881, Validation loss 0.5721\n",
      "Epoch 1200, Training loss 0.4756, Validation loss 0.5799\n",
      "Epoch 1300, Training loss 0.4840, Validation loss 0.5270\n",
      "Epoch 1400, Training loss 0.4552, Validation loss 0.5413\n",
      "Epoch 1500, Training loss 0.4677, Validation loss 0.5472\n",
      "Epoch 1600, Training loss 0.4542, Validation loss 0.5224\n",
      "Early stopping at epoch 1678\n",
      "submission.csv saved.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>██▇▆▅▅▆▆▆▅▅▅▄▄▄▄▃▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>Validation loss</td><td>██▇▇▅▅▅▄▅▆▄▅▄▅▄▄▅▄▄▃▄▃▃▂▂▂▂▃▃▃▃▂▂▂▃▃▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1678</td></tr><tr><td>Training loss</td><td>0.43351</td></tr><tr><td>Validation loss</td><td>0.51972</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-25_00-15-03</strong> at: <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/v3izceum' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/v3izceum</a><br/> View project at: <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241025_001503-v3izceum\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd  ##submission.csv 생성을 위한 pandas\n",
    "from pathlib import Path\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "BASE_PATH = str(Path(os.getcwd()).resolve().parent.parent)\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_your_code.hw2.titanic_dataset import TitanicDataset\n",
    "from _03_your_code.hw2.titanic_dataset import get_preprocessed_dataset\n",
    "from _03_your_code.hw2.titanic_dataset import TitanicTestDataset\n",
    "\n",
    "def get_data():\n",
    "    train_X, train_y, test_X = get_preprocessed_dataset()\n",
    "\n",
    "    # Create a training dataset using TitanicDataset class\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "\n",
    "    ##test dataset에 대한 dataloader 추가\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "    print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "    return train_data_loader, validation_data_loader, test_data_loader\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential( ##활성화 함수 수정해보기\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], wandb.config.n_hidden_unit_list[2]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[2]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[2], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def get_model_and_optimizer():\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "    optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "    return my_model, optimizer\n",
    "\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader, test_data_loader):\n",
    "    n_epochs = wandb.config.epochs\n",
    "    loss_fn = nn.CrossEntropyLoss()  ##loss 함수 수정해보기\n",
    "    next_print_epoch = 100\n",
    "    best_validation_loss = float('inf')  ## early stop을 위한 변수\n",
    "    early_stop_patience = 200  ## 몇 epoch 동안 개선이 없으면 멈출지 결정\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        num_trains = 0\n",
    "        for train_batch in train_data_loader:\n",
    "            input = train_batch['input']\n",
    "            target = train_batch['target']\n",
    "            output_train = model(input)\n",
    "            loss = loss_fn(output_train, target)\n",
    "            loss_train += loss.item()\n",
    "            num_trains += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_validation = 0.0\n",
    "        num_validations = 0\n",
    "        with torch.no_grad():\n",
    "            for validation_batch in validation_data_loader:\n",
    "                input = validation_batch['input']\n",
    "                target = validation_batch['target']\n",
    "                output_validation = model(input)\n",
    "                loss = loss_fn(output_validation, target)\n",
    "                loss_validation += loss.item()\n",
    "                num_validations += 1\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Training loss\": loss_train / num_trains,\n",
    "            \"Validation loss\": loss_validation / num_validations\n",
    "        })\n",
    "\n",
    "        if epoch >= next_print_epoch:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, \"\n",
    "                f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "                f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "            )\n",
    "            next_print_epoch += 100\n",
    "\n",
    "        ## Early stopping 조건 확인\n",
    "        avg_validation_loss = loss_validation / num_validations\n",
    "        if avg_validation_loss < best_validation_loss:\n",
    "            best_validation_loss = avg_validation_loss\n",
    "            patience_counter = 0  ## 개선되면 patience 초기화\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    ## 테스트 데이터에 대해 예측하고 submission.csv 생성\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for test_batch in test_data_loader:\n",
    "            input = test_batch['input']\n",
    "            output = model(input)\n",
    "            predicted_classes = output.argmax(dim=1)  ## 각 클래스 확률 중 가장 큰 값 선택\n",
    "            predictions.extend(predicted_classes.tolist())\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': list(range(892, 892 + len(predictions))),  ## 예시로 PassengerId를 892번부터 시작하도록 설정\n",
    "        'Survived': predictions\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"submission.csv saved.\")\n",
    "\n",
    "def main(args):\n",
    "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 1e-3,\n",
    "        'n_hidden_unit_list': [128, 64, 32],\n",
    "    }\n",
    "\n",
    "    wandb.init(\n",
    "        mode=\"online\",\n",
    "        project=\"titanic_training\",\n",
    "        notes=\"titanic wandb experiment\",\n",
    "        tags=[\"my_model\", \"titanic\"],\n",
    "        name=current_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    train_data_loader, validation_data_loader, test_data_loader = get_data()\n",
    "\n",
    "    linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "    training_loop(\n",
    "        model=linear_model,\n",
    "        optimizer=optimizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        validation_data_loader=validation_data_loader,\n",
    "        test_data_loader=test_data_loader\n",
    "    )\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        sys.argv = sys.argv[:1]\n",
    "      \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--wandb\", action=argparse.BooleanOptionalAction, default=False, help=\"True or False\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-b\", \"--batch_size\", type=int, default=256, help=\"Batch size (int, default: 256)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-e\", \"--epochs\", type=int, default=10_000, help=\"Number of training epochs (int, default:10_000)\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c539afa1068055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T03:03:03.936360Z",
     "start_time": "2024-10-25T03:02:06.276247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\user\\git\\link_dl\\_03_your_code\\hw2\\wandb\\run-20241025_120206-4dgtkh8r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/4dgtkh8r' target=\"_blank\">2024-10-25_12-02-06</a></strong> to <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/4dgtkh8r' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/4dgtkh8r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=False, batch_size=256, epochs=4000)\n",
      "{'epochs': 4000, 'batch_size': 256, 'learning_rate': 0.001, 'n_hidden_unit_list': [128, 64, 32]}\n",
      "713 178 418\n",
      "Epoch 100, Training loss 0.6549, Validation loss 0.6339\n",
      "Epoch 200, Training loss 0.6435, Validation loss 0.6182\n",
      "Epoch 300, Training loss 0.6281, Validation loss 0.6026\n",
      "Epoch 400, Training loss 0.6066, Validation loss 0.5985\n",
      "Epoch 500, Training loss 0.6027, Validation loss 0.5734\n",
      "Epoch 600, Training loss 0.5972, Validation loss 0.5591\n",
      "Epoch 700, Training loss 0.6118, Validation loss 0.5813\n",
      "Epoch 800, Training loss 0.6058, Validation loss 0.5777\n",
      "Epoch 900, Training loss 0.5915, Validation loss 0.5678\n",
      "Epoch 1000, Training loss 0.5734, Validation loss 0.5632\n",
      "Epoch 1100, Training loss 0.5643, Validation loss 0.5527\n",
      "Epoch 1200, Training loss 0.5755, Validation loss 0.5573\n",
      "Epoch 1300, Training loss 0.5705, Validation loss 0.5394\n",
      "Epoch 1400, Training loss 0.5696, Validation loss 0.5621\n",
      "Epoch 1500, Training loss 0.5758, Validation loss 0.5474\n",
      "Epoch 1600, Training loss 0.5630, Validation loss 0.5236\n",
      "Epoch 1700, Training loss 0.5749, Validation loss 0.5345\n",
      "Epoch 1800, Training loss 0.5553, Validation loss 0.5180\n",
      "Epoch 1900, Training loss 0.5302, Validation loss 0.5032\n",
      "Epoch 2000, Training loss 0.5403, Validation loss 0.5296\n",
      "Epoch 2100, Training loss 0.5402, Validation loss 0.4995\n",
      "Epoch 2200, Training loss 0.5397, Validation loss 0.4965\n",
      "Epoch 2300, Training loss 0.5243, Validation loss 0.5076\n",
      "Epoch 2400, Training loss 0.5148, Validation loss 0.4834\n",
      "Epoch 2500, Training loss 0.5066, Validation loss 0.5076\n",
      "Epoch 2600, Training loss 0.5104, Validation loss 0.5241\n",
      "Epoch 2700, Training loss 0.5224, Validation loss 0.5165\n",
      "Epoch 2800, Training loss 0.5158, Validation loss 0.5093\n",
      "Epoch 2900, Training loss 0.4935, Validation loss 0.4722\n",
      "Epoch 3000, Training loss 0.5015, Validation loss 0.4823\n",
      "Epoch 3100, Training loss 0.4913, Validation loss 0.4747\n",
      "Epoch 3200, Training loss 0.4919, Validation loss 0.4923\n",
      "Epoch 3300, Training loss 0.4761, Validation loss 0.4628\n",
      "Epoch 3400, Training loss 0.4718, Validation loss 0.4818\n",
      "Epoch 3500, Training loss 0.4640, Validation loss 0.4611\n",
      "Epoch 3600, Training loss 0.4742, Validation loss 0.4551\n",
      "Epoch 3700, Training loss 0.4662, Validation loss 0.4250\n",
      "Epoch 3800, Training loss 0.4622, Validation loss 0.4637\n",
      "Epoch 3900, Training loss 0.4798, Validation loss 0.4395\n",
      "Epoch 4000, Training loss 0.4520, Validation loss 0.4586\n",
      "submission.csv saved.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▅▆▆▆▅▅▄▄▄▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▃▂▂▂▁▂▂▂▁▁</td></tr><tr><td>Validation loss</td><td>█▆▆▅▅▅▄▅▄▅▄▄▃▄▄▃▃▃▃▂▃▃▃▂▂▃▂▃▃▂▂▂▂▃▃▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>4000</td></tr><tr><td>Training loss</td><td>0.45205</td></tr><tr><td>Validation loss</td><td>0.45864</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-25_12-02-06</strong> at: <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/4dgtkh8r' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training/runs/4dgtkh8r</a><br/> View project at: <a href='https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/jmyoon110-korea-university-of-technology-and-education/titanic_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241025_120206-4dgtkh8r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd  ##submission.csv 생성을 위한 pandas\n",
    "from pathlib import Path\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "BASE_PATH = str(Path(os.getcwd()).resolve().parent.parent)\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_your_code.hw2.titanic_dataset import TitanicDataset\n",
    "from _03_your_code.hw2.titanic_dataset import get_preprocessed_dataset\n",
    "from _03_your_code.hw2.titanic_dataset import TitanicTestDataset\n",
    "\n",
    "def get_data():\n",
    "    train_X, train_y, test_X = get_preprocessed_dataset()\n",
    "\n",
    "    # Create a training dataset using TitanicDataset class\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "\n",
    "    ##test dataset에 대한 dataloader 추가\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "    print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "    return train_data_loader, validation_data_loader, test_data_loader\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential( ##활성화 함수 수정해보기\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], wandb.config.n_hidden_unit_list[2]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[2]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[2], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def get_model_and_optimizer():\n",
    "    ##my_model = MyModel(n_input=11, n_output=1)\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "    optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "    return my_model, optimizer\n",
    "\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader, test_data_loader):\n",
    "    n_epochs = wandb.config.epochs\n",
    "    ##loss_fn = nn.BCEWithLogitsLoss()  ##loss 함수 수정해보기    \n",
    "    loss_fn = nn.CrossEntropyLoss()  ##loss 함수 수정해보기\n",
    "    next_print_epoch = 100\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        num_trains = 0\n",
    "        for train_batch in train_data_loader:\n",
    "            input = train_batch['input']\n",
    "            target = train_batch['target']\n",
    "            ##target = target.unsqueeze(1)\n",
    "            output_train = model(input)\n",
    "            loss = loss_fn(output_train, target)\n",
    "\n",
    "            ##loss = loss_fn(output_train, target.float())\n",
    "            loss_train += loss.item()\n",
    "            num_trains += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_validation = 0.0\n",
    "        num_validations = 0\n",
    "        with torch.no_grad():\n",
    "            for validation_batch in validation_data_loader:\n",
    "                input = validation_batch['input']\n",
    "                target = validation_batch['target']\n",
    "                ##target = target.unsqueeze(1)\n",
    "                output_validation = model(input)\n",
    "                loss = loss_fn(output_validation, target)\n",
    "                ##loss = loss_fn(output_validation, target.float())\n",
    "                loss_validation += loss.item()\n",
    "                num_validations += 1\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Training loss\": loss_train / num_trains,\n",
    "            \"Validation loss\": loss_validation / num_validations\n",
    "        })\n",
    "\n",
    "        if epoch >= next_print_epoch:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, \"\n",
    "                f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "                f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "            )\n",
    "            next_print_epoch += 100\n",
    "\n",
    "    ## 테스트 데이터에 대해 예측하고 submission.csv 생성\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for test_batch in test_data_loader:\n",
    "            input = test_batch['input']\n",
    "            output = model(input)\n",
    "            predicted_classes = output.argmax(dim=1)  ## 각 클래스 확률 중 가장 큰 값 선택\n",
    "            predictions.extend(predicted_classes.tolist())\n",
    "\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': list(range(892, 892 + len(predictions))),  ## 예시로 PassengerId를 892번부터 시작하도록 설정\n",
    "        'Survived': predictions\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"submission.csv saved.\")\n",
    "\n",
    "def main(args):\n",
    "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 1e-3,\n",
    "        'n_hidden_unit_list': [128, 64, 32],\n",
    "    }\n",
    "\n",
    "    wandb.init(\n",
    "        mode=\"online\",\n",
    "        project=\"titanic_training\",\n",
    "        notes=\"titanic wandb experiment\",\n",
    "        tags=[\"my_model\", \"titanic\"],\n",
    "        name=current_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    train_data_loader, validation_data_loader, test_data_loader = get_data()\n",
    "\n",
    "    linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "    training_loop(\n",
    "        model=linear_model,\n",
    "        optimizer=optimizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        validation_data_loader=validation_data_loader,\n",
    "        test_data_loader=test_data_loader\n",
    "    )\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        sys.argv = sys.argv[:1]\n",
    "      \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--wandb\", action=argparse.BooleanOptionalAction, default=False, help=\"True or False\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-b\", \"--batch_size\", type=int, default=256, help=\"Batch size (int, default: 256)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-e\", \"--epochs\", type=int, default=4_000, help=\"Number of training epochs (int, default:4_000)\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fae775670f54fd",
   "metadata": {},
   "source": [
    "- 5000, 10000번 정도의 에포크를 주고 모델을 많이 학습시켜본 결과, 경험적으로 4000 에포크 정도일 때가 제일 적합하다고 생각했다. 과적합이 크게 발생하지 않으면서도 과적합된 결과의 submission 값과 큰 차이가 나지 않았기 때문이다. \n",
    "- 과적합된 모델이 더 나은 예측 결과를 내는 이유에 대해서 찾아본 결과, 훈련 데이터에서 학습한 복잡한 패턴들이 테스트 데이터에서 운좋게 맞아 떨어지는 경우가 많이 생겨서 더 나은 결과를 낼 수 있다고 한다. 하지만 일반화 능력이 떨어지기 때문에 좋은 모델이라고 볼 수는 없으므로 위 결과처럼 train loss와 validation loss가 크게 차이나지 않는 결과가 나오는 것이 좋을 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728637dafad5eee",
   "metadata": {},
   "source": [
    "# **요구사항 4: submission.csv 제출 및 등수 확인**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ab0a684f6a93",
   "metadata": {},
   "source": [
    "최고 점수\n",
    "![윤정민_titanic_score](https://drive.google.com/file/d/1LD-KEewZjLhtd5Q5OBqIV8x1zv0P-ioL/view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b5384d94ee7fa",
   "metadata": {},
   "source": "숙제 후기: 이번 과제를 하면서 하이퍼 파라미터, 활성화 함수 등 여러 조건들을 변경해보면서 loss를 줄이고 정확도를 높이는 방법에 대해서 알 수 있었다. Dropout과 BatchNorm1d의 기능과 장점에 대해서도 알 수 있었다. 학교 수업에서 보던 것처럼 early stop을 통해 최적의 상황에서 멈추고 좋은 결과를 얻어보려고 했는데, 잘 되지 않아서 아쉽다. 처음 kaggle에 제출했을 때는 점수가 0.6정도가 나오고, loss 결과들도 0.6으로 꽤 높게 나왔었다. loss를 최대한 줄일 수 있는 방법으로 여러 방법을 시도해보고 많은 모델을 만들어본 결과, loss를 0.4까지 줄일 수 있게 돼서 뿌듯했다. training loss 뿐만 아니라 validation loss도 같이 비슷하게 줄었을 때의 기분은 정말 좋았다. kaggle 아이디를 여러 개 만들어서 많이 제출해봤는데 점수가 0.775점까지 나올 수 있었고, 과적합 없는 4000번의 에포크를 거친 모델에서도 대부분 0.75정도가 나와서 이정도면 나름의 결과를 얻어낸 것이라는 생각이 들었다. 코드를 작성할 때도 계속 에러가 생겨서 힘들었지만 다행히 잘 해결했다. 그리고 BCEWithLogits를 사용하지 않고 CrossEntropy를 사용한다는 점도 신기했다. 실제로 두 함수를 모두 사용해보았는데 CrossEntropy를 사용했을 때의 결과가 좀 더 좋았다. 이런 경험을 하고 나니 딥러닝을 할 때, 하이퍼 파라미터나 loss 함수 등 정말 많은 조건들을 최적화 하는 것이 제일 어려울 것 같다고 느꼈다. "
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
